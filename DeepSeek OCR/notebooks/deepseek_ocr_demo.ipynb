{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# DeepSeek OCR on Amazon SageMaker\n",
    "\n",
    "This notebook demonstrates how to deploy and use **DeepSeek OCR** on Amazon SageMaker with two types of endpoints:\n",
    "\n",
    "## Endpoint Types\n",
    "\n",
    "### 1. Async Endpoint (Recommended for Production)\n",
    "- **Timeout**: 15+ minutes\n",
    "- **Best for**: Large PDFs (100+ pages), batch processing, background jobs\n",
    "- **Method**: `invoke_endpoint_async()` with S3 input/output\n",
    "- **Benefits**: Scales to zero, handles large workloads, no result truncation\n",
    "\n",
    "### 2. Sync Endpoint\n",
    "- **Timeout**: 60 seconds\n",
    "- **Best for**: Single images, small documents, real-time UI\n",
    "- **Method**: `invoke_endpoint()` with direct JSON\n",
    "- **Benefits**: Immediate response, simpler workflow\n",
    "\n",
    "## What is DeepSeek OCR?\n",
    "\n",
    "DeepSeek OCR is a state-of-the-art vision-language model for optical character recognition:\n",
    "- Extract text from images (documents, invoices, receipts, whiteboards)\n",
    "- Convert documents to structured formats like Markdown\n",
    "- Process multi-page PDFs\n",
    "- Provide bounding box coordinates (grounding mode)\n",
    "\n",
    "**Model**: [deepseek-ai/DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) (3B parameters)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook:\n",
    "1. Build and push the Docker image to ECR using CodeBuild\n",
    "2. Ensure your SageMaker execution role has permissions for ECR, S3, and SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Deploy Async Endpoint\n",
    "\n",
    "We'll deploy an **Async Inference endpoint** using SageMaker's `AsyncInferenceConfig`. This enables:\n",
    "- Processing times up to 15+ minutes\n",
    "- Automatic S3 storage for results\n",
    "- Auto-scaling to zero when idle\n",
    "- Cost-effective batch processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Setup\n",
    "region = boto3.Session().region_name\n",
    "account = boto3.client('sts').get_caller_identity()['Account']\n",
    "image = f\"{account}.dkr.ecr.{region}.amazonaws.com/deepseek-ocr-sagemaker-byoc:latest\"\n",
    "role = get_execution_role()\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Account: {account}\")\n",
    "print(f\"Image URI: {image}\")\n",
    "print(f\"Role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-s3-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup S3 buckets for async inference\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define bucket names\n",
    "async_input_bucket = f\"sagemaker-async-{region}-{account}\"\n",
    "async_output_bucket = f\"sagemaker-async-output-{region}-{account}\"\n",
    "\n",
    "print(\"Creating S3 buckets for async inference...\")\n",
    "\n",
    "# Create input bucket\n",
    "try:\n",
    "    s3.create_bucket(\n",
    "        Bucket=async_input_bucket,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "    )\n",
    "    print(f\"✓ Created input bucket: {async_input_bucket}\")\n",
    "except s3.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(f\"✓ Input bucket already exists: {async_input_bucket}\")\n",
    "\n",
    "# Create output bucket\n",
    "try:\n",
    "    s3.create_bucket(\n",
    "        Bucket=async_output_bucket,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "    )\n",
    "    print(f\"✓ Created output bucket: {async_output_bucket}\")\n",
    "except s3.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(f\"✓ Output bucket already exists: {async_output_bucket}\")\n",
    "\n",
    "print(\"\\n✅ S3 buckets ready for async inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-names",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique names for async endpoint\n",
    "async_model_name = f\"deepseek-ocr-async-{int(time.time())}\"\n",
    "async_endpoint_config_name = f\"{async_model_name}-cfg\"\n",
    "async_endpoint_name = f\"{async_model_name}-ep\"\n",
    "\n",
    "print(f\"Async Model Name: {async_model_name}\")\n",
    "print(f\"Async Endpoint Config: {async_endpoint_config_name}\")\n",
    "print(f\"Async Endpoint Name: {async_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create async model (same container as sync endpoint)\n",
    "print(\"Creating async SageMaker model...\")\n",
    "sm.create_model(\n",
    "    ModelName=async_model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        'Image': image,\n",
    "        'Mode': 'SingleModel',\n",
    "        'Environment': {\n",
    "            'MODEL_ID': 'deepseek-ai/DeepSeek-OCR',\n",
    "            'HF_HUB_ENABLE_HF_TRANSFER': '1'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"✓ Async model created: {async_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create async endpoint configuration\n",
    "print(\"Creating async endpoint configuration...\")\n",
    "\n",
    "sm.create_endpoint_config(\n",
    "    EndpointConfigName=async_endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'VariantName': 'AllTraffic',\n",
    "        'ModelName': async_model_name,\n",
    "        'InitialInstanceCount': 1,\n",
    "        'InstanceType': 'ml.g5.2xlarge'\n",
    "    }],\n",
    "    AsyncInferenceConfig={  # ← THIS MAKES IT ASYNC!\n",
    "        'OutputConfig': {\n",
    "            'S3OutputPath': f\"s3://{async_output_bucket}/async-results/\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ Async endpoint config created: {async_endpoint_config_name}\")\n",
    "print(f\"  Output S3: s3://{async_output_bucket}/async-results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-endpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create async endpoint\n",
    "print(\"Creating async endpoint (this takes ~5-10 minutes)...\")\n",
    "sm.create_endpoint(\n",
    "    EndpointName=async_endpoint_name,\n",
    "    EndpointConfigName=async_endpoint_config_name\n",
    ")\n",
    "print(f\"✓ Async endpoint creation started: {async_endpoint_name}\")\n",
    "print(\"\\nWaiting for async endpoint to be in service...\")\n",
    "\n",
    "# Wait for endpoint\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=async_endpoint_name)\n",
    "\n",
    "print(f\"\\n✅ Async endpoint is ready: {async_endpoint_name}\")\n",
    "print(f\"   Input bucket: s3://{async_input_bucket}/\")\n",
    "print(f\"   Output bucket: s3://{async_output_bucket}/async-results/\")\n",
    "print(\"\\nThis endpoint supports:\")\n",
    "print(\"  ✓ Up to 15+ minute processing\")\n",
    "print(\"  ✓ invoke_endpoint_async() method\")\n",
    "print(\"  ✓ S3-based input/output\")\n",
    "print(\"  ✓ Automatic result storage (no truncation)\")\n",
    "print(\"  ✓ Scales to zero when idle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-test-header",
   "metadata": {},
   "source": [
    "## 2. Test Async Endpoint\n",
    "\n",
    "The async workflow involves:\n",
    "1. Encode image/PDF to base64 and create JSON payload\n",
    "2. Upload JSON to S3 input bucket\n",
    "3. Call `invoke_endpoint_async()` with S3 input location\n",
    "4. Poll S3 output bucket for results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "# Setup runtime client for async inference\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def process_async(file_path, prompt=\"<image>\\nFree OCR.\"):\n",
    "    \"\"\"Complete async workflow for image or PDF\"\"\"\n",
    "    \n",
    "    # Step 1: Read and encode file\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file_data = f.read()\n",
    "        file_base64 = base64.b64encode(file_data).decode('utf-8')\n",
    "    \n",
    "    # Step 2: Create JSON payload\n",
    "    is_pdf = file_path.lower().endswith('.pdf')\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"pdf_base64\" if is_pdf else \"image_base64\": file_base64\n",
    "    }\n",
    "    \n",
    "    # Step 3: Upload to S3\n",
    "    s3_key = f\"inputs/{Path(file_path).stem}.json\"\n",
    "    s3.put_object(\n",
    "        Bucket=async_input_bucket,\n",
    "        Key=s3_key,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json'\n",
    "    )\n",
    "    input_location = f\"s3://{async_input_bucket}/{s3_key}\"\n",
    "    print(f\"  ✓ Uploaded to: {input_location}\")\n",
    "    \n",
    "    # Step 4: Invoke async\n",
    "    print(f\"  ✓ Invoking async endpoint...\")\n",
    "    response = runtime.invoke_endpoint_async(\n",
    "        EndpointName=async_endpoint_name,\n",
    "        InputLocation=input_location,\n",
    "        ContentType='application/json'\n",
    "    )\n",
    "    output_location = response['OutputLocation']\n",
    "    print(f\"  ✓ Request submitted: {output_location}\")\n",
    "    \n",
    "    # Step 5: Wait for result\n",
    "    parsed = urlparse(output_location)\n",
    "    bucket = parsed.netloc\n",
    "    key = parsed.path.lstrip('/')\n",
    "    \n",
    "    print(f\"  ⏳ Waiting for result...\")\n",
    "    start = time.time()\n",
    "    max_wait = 900  # 15 minutes\n",
    "    \n",
    "    while time.time() - start < max_wait:\n",
    "        try:\n",
    "            obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "            result = json.loads(obj['Body'].read())\n",
    "            elapsed = int(time.time() - start)\n",
    "            print(f\"  ✅ Result ready after {elapsed}s!\\n\")\n",
    "            return result\n",
    "        except s3.exceptions.NoSuchKey:\n",
    "            time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Error: {e}\")\n",
    "            time.sleep(10)\n",
    "    \n",
    "    print(f\"  ⏱ Timeout after {max_wait}s\")\n",
    "    return None\n",
    "\n",
    "print(\"✓ Async helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-ex1-header",
   "metadata": {},
   "source": [
    "### Example 1: Invoice Processing\n",
    "\n",
    "Process a business invoice using the async endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-ex1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process invoice with async endpoint\n",
    "result = process_async(\"Invoice_3.jpg\")\n",
    "\n",
    "if result:\n",
    "    print(\"OCR Result:\")\n",
    "    print(\"=\" * 80)\n",
    "    text = result['text']\n",
    "    if len(text) > 1000:\n",
    "        print(text[:1000])\n",
    "        print(f\"\\n... (truncated, full text in S3)\")\n",
    "    else:\n",
    "        print(text)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal length: {len(text)} characters\")\n",
    "else:\n",
    "    print(\"❌ Failed to get result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "async-ex2-header",
   "metadata": {},
   "source": [
    "### Example 2: Multi-Page PDF\n",
    "\n",
    "Process a research paper PDF with multiple pages. This demonstrates the async endpoint's ability to handle long-running tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "async-ex2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDF with async endpoint\n",
    "result = process_async(\"1706.03762v7.pdf\")\n",
    "\n",
    "if result:\n",
    "    print(\"OCR Result:\")\n",
    "    print(\"=\" * 80)\n",
    "    text = result['text']\n",
    "    print(text[:1000])\n",
    "    if len(text) > 1000:\n",
    "        print(f\"\\n... (showing first 1000 of {len(text)} characters)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nPages: {result.get('pages', 'N/A')}\")\n",
    "    print(f\"Total length: {len(text)} characters\")\n",
    "    print(\"\\n✅ Full OCR text stored in S3 - no truncation!\")\n",
    "else:\n",
    "    print(\"❌ Failed to get result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sync-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Deploy Sync Endpoint (Optional)\n",
    "\n",
    "For real-time applications requiring immediate responses, deploy a synchronous endpoint. Note the 60-second timeout limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-names",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique names for resources\n",
    "model_name = f\"deepseek-ocr-byoc-{int(time.time())}\"\n",
    "endpoint_config_name = f\"{model_name}-cfg\"\n",
    "endpoint_name = f\"{model_name}-ep\"\n",
    "\n",
    "print(f\"Model Name: {model_name}\")\n",
    "print(f\"Endpoint Config: {endpoint_config_name}\")\n",
    "print(f\"Endpoint Name: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker Model\n",
    "print(\"Creating SageMaker model...\")\n",
    "sm.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        'Image': image,\n",
    "        'Mode': 'SingleModel',\n",
    "        'Environment': {\n",
    "            'MODEL_ID': 'deepseek-ai/DeepSeek-OCR',\n",
    "            'HF_HUB_ENABLE_HF_TRANSFER': '1'\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"✓ Model created: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Endpoint Configuration\n",
    "print(\"Creating endpoint configuration...\")\n",
    "sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.g5.2xlarge'  # 24GB GPU, 8 vCPUs, 32GB RAM\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f\"✓ Endpoint config created: {endpoint_config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sync-endpoint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and wait for sync endpoint\n",
    "print(\"Creating sync endpoint (this takes ~5-10 minutes)...\")\n",
    "sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"✓ Endpoint creation started: {endpoint_name}\")\n",
    "print(\"\\nWaiting for endpoint to be in service...\")\n",
    "\n",
    "# Wait for endpoint\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(f\"\\n✓ Sync endpoint is ready: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sync-test-header",
   "metadata": {},
   "source": [
    "## 4. Test Sync Endpoint\n",
    "\n",
    "Test the sync endpoint with a single invoice example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup runtime client for inference\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def invoke_ocr(payload):\n",
    "    \"\"\"Helper function to invoke the endpoint\"\"\"\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=json.dumps(payload)\n",
    "    )\n",
    "    return json.loads(response['Body'].read())\n",
    "\n",
    "print(\"✓ Helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sync-ex1-header",
   "metadata": {},
   "source": [
    "### Example: Invoice Processing\n",
    "\n",
    "Process an invoice with immediate response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example1-invoice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read local invoice image\n",
    "invoice_path = Path(\"Invoice_3.jpg\")\n",
    "with open(invoice_path, \"rb\") as f:\n",
    "    img_data = f.read()\n",
    "    img_base64 = base64.b64encode(img_data).decode(\"utf-8\")\n",
    "\n",
    "payload = {\n",
    "    \"prompt\": \"<image>\\nFree OCR.\",\n",
    "    \"image_base64\": img_base64\n",
    "}\n",
    "\n",
    "print(f\"Processing invoice image ({invoice_path.stat().st_size / 1024:.1f} KB)...\\n\")\n",
    "result = invoke_ocr(payload)\n",
    "\n",
    "print(\"✅ SUCCESS!\\n\")\n",
    "print(\"OCR Result:\")\n",
    "print(\"=\" * 80)\n",
    "# Show first 1000 characters if output is long\n",
    "text = result[\"text\"]\n",
    "if len(text) > 1000:\n",
    "    print(text[:1000])\n",
    "    print(\"\\n... (truncated) ...\")\n",
    "else:\n",
    "    print(text)\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal length: {len(text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Cleanup Resources\n",
    "\n",
    "**Important**: SageMaker endpoints incur charges while running (~$1.52/hour per endpoint). Delete endpoints when not in use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-resources",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display current resources\n",
    "print(\"Sync Endpoint Resources:\")\n",
    "print(f\"  Endpoint: {endpoint_name}\")\n",
    "print(f\"  Endpoint Config: {endpoint_config_name}\")\n",
    "print(f\"  Model: {model_name}\")\n",
    "\n",
    "print(\"\\nAsync Endpoint Resources:\")\n",
    "print(f\"  Endpoint: {async_endpoint_name}\")\n",
    "print(f\"  Endpoint Config: {async_endpoint_config_name}\")\n",
    "print(f\"  Model: {async_model_name}\")\n",
    "\n",
    "print(\"\\nRun the next cell to delete these resources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete sync endpoint resources\n",
    "print(\"=\" * 80)\n",
    "print(\"Cleaning up SYNC endpoint resources...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    print(\"Deleting sync endpoint...\")\n",
    "    sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "    print(f\"✓ Sync endpoint deleted: {endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not delete sync endpoint: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Deleting sync endpoint configuration...\")\n",
    "    sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "    print(f\"✓ Sync endpoint config deleted: {endpoint_config_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not delete sync endpoint config: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Deleting sync model...\")\n",
    "    sm.delete_model(ModelName=model_name)\n",
    "    print(f\"✓ Sync model deleted: {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not delete sync model: {e}\")\n",
    "\n",
    "# Delete async endpoint resources\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Cleaning up ASYNC endpoint resources...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    print(\"Deleting async endpoint...\")\n",
    "    sm.delete_endpoint(EndpointName=async_endpoint_name)\n",
    "    print(f\"✓ Async endpoint deleted: {async_endpoint_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not delete async endpoint: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Deleting async endpoint configuration...\")\n",
    "    sm.delete_endpoint_config(EndpointConfigName=async_endpoint_config_name)\n",
    "    print(f\"✓ Async endpoint config deleted: {async_endpoint_config_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not delete async endpoint config: {e}\")\n",
    "\n",
    "try:\n",
    "    print(\"Deleting async model...\")\n",
    "    sm.delete_model(ModelName=async_model_name)\n",
    "    print(f\"✓ Async model deleted: {async_model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not delete async model: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Cleanup completed!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nAll resources have been deleted. No more charges will incur.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ✓ Deploying **Async Inference endpoint** with AsyncInferenceConfig\n",
    "- ✓ Processing documents with S3-based async workflow\n",
    "- ✓ Handling large PDFs with 15+ minute timeout\n",
    "- ✓ Deploying **Sync endpoint** for real-time processing\n",
    "- ✓ Managing and cleaning up SageMaker resources\n",
    "\n",
    "### When to Use Each Endpoint\n",
    "\n",
    "| Use Case | Endpoint Type | Reason |\n",
    "|----------|---------------|--------|\n",
    "| Single image | Sync | Fast (2-5s) response |\n",
    "| Real-time UI | Sync | Immediate feedback |\n",
    "| Large PDF (10+ pages) | Async | Avoids timeout |\n",
    "| Batch processing | Async | Cost-effective scaling |\n",
    "| Background jobs | Async | Fire-and-forget |\n",
    "\n",
    "### Production Enhancements\n",
    "\n",
    "For production use:\n",
    "1. **Configure SNS topics** - Get notifications when async jobs complete\n",
    "2. **Set up auto-scaling** - Handle variable workloads\n",
    "3. **Add S3 lifecycle policies** - Auto-delete old results\n",
    "4. **Monitor with CloudWatch** - Track processing times and costs\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Model**: [DeepSeek-AI/DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR)\n",
    "- **SageMaker Async Inference**: [AWS Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html)\n",
    "- **SageMaker BYOC**: [Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
